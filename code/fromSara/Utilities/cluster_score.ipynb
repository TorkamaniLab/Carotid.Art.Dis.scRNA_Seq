{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a function that returns modularity-type scoring for individual clusters in a graph.\n",
    "### Clusters with a higher ratio of edge weights inside the cluster vs connecting to other\n",
    "### clusters will recieve a higher score. Clusters are scored on the scale of 0(worst) to 1(best).\n",
    "\n",
    "### This function requires, at minimum, an igraph object with an edge attribute of 'pcor'.\n",
    "\n",
    "## This function generates clusters through walktrap and cutreeDynamic. \n",
    "### Use parameter 't' to set walk length and 'minclusts' to set minimum cluster size.\n",
    "### Previously generated clusters (through any method, not just walktrap) can be imputed as \n",
    "### a membership vector through the parameter 'clusters'.\n",
    "\n",
    "## If you want to calculate cluster size, set 'sizes = TRUE'\n",
    "\n",
    "## If you want to calculate maximum strength per cluster, set 'max.str = TRUE'\n",
    "\n",
    "## If you want to calculate p.value, set 'calculate.p = TRUE'\n",
    "### This function uses a monte carlo simulation to calculate p values. If you already generated a null \n",
    "### set, pass it to the function through the 'nulldist' parameter. If you have not, the function will\n",
    "### generate 1000 random clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This executes a system command\n",
    "## Note that the environment path is incorrect and needs to be fixed for commands to work\n",
    "## nbconvert needs this code\n",
    "\n",
    "Sys.setenv(PATH = paste(\"/usr/lib64/qt-3.3/bin:/opt/applications/cytoscape/\",\n",
    "                        \"3.3.0:/opt/applications/R/3.5.1/gnu/bin:/opt/applications/\",\n",
    "                        \"gcc/4.9.4/bin:/opt/applications/java/jdk1.8.0_65/bin:/opt/\",\n",
    "                        \"applications/ant/apache-ant-1.9.0/bin:/opt/applications/\",\n",
    "                        \"python/3.6.3/gnu/bin:/usr/local/go/bin:/usr/local/sbin:/\",\n",
    "                        \"usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/\",\n",
    "                        \"bin:/usr/lpp/mmfs/bin:/root/bin:/usr/local/bin:/usr/lpp/mmfs/bin\",\n",
    "                       sep = ''))\n",
    "\n",
    "osc <- function (cmd) {\n",
    "    scra <- '/gpfs/group/torkamani/devans/GTEx/Scratch.Area/' # Location of temporary files\n",
    "    fullcmd <- paste(cmd, ' >& ', scra, 'temp.txt', sep = '')\n",
    "    system(fullcmd)\n",
    "    lines <- readLines(paste(scra, 'temp.txt', sep = ''))\n",
    "    system(paste('rm ', scra, 'temp.txt', sep = ''))\n",
    "    return(lines)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_score <- function(net, clusters = NULL, sizes = FALSE, max.str = FALSE, t = 10, minclusts = 30, calculate.p = FALSE, nulldist = NULL){\n",
    "    \n",
    "    #load packages\n",
    "    library(igraph)\n",
    "    library(corpcor)\n",
    "    library(WGCNA)\n",
    "    \n",
    "    # generate clusters\n",
    "    if(is.null(clusters)){\n",
    "        wt <- cluster_walktrap(net, weights = E(net)$pcor, steps = t,\n",
    "                            merges = TRUE, modularity = TRUE, membership = TRUE)\n",
    "        hclust <- as.hclust(wt)\n",
    "        dyntree <- cutreeDynamic(hclust, method = 'tree', minClusterSize = minclusts)\n",
    "        clusters <- dyntree\n",
    "    }\n",
    "    \n",
    "    # generate null distribution\n",
    "    if(calculate.p & is.null(nulldist)){\n",
    "        randperms <- vector(mode = 'numeric', length = 1000)\n",
    "        for(i in 1:1000) {\n",
    "            samplenamesrand <- sample(V(net)$name, size = minclusts)\n",
    "            just1clustrand <- induced_subgraph(net, V(net)$name %in% samplenamesrand)\n",
    "            clustedgesrand <- E(net)[E(net) %in% unlist(incident_edges(net, V(net)$name %in% samplenamesrand))]\n",
    "            internalsumrand <- sum(abs(E(just1clustrand)$pcor))\n",
    "            totalsumrand <- sum(abs(clustedgesrand$pcor))\n",
    "            clusterscorerand <- internalsumrand/totalsumrand\n",
    "            randperms[i] <- clusterscorerand\n",
    "            nulldist <- randperms\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # generate cluster score \n",
    "    V(net)$clusters <- clusters\n",
    "    scoresvec <- vector(mode = 'numeric', length = length(unique(clusters)))\n",
    "    names(scoresvec) <- unique(clusters)[order(unique(clusters))]\n",
    "    count <- 1\n",
    "    for(j in unique(clusters)[order(unique(clusters))]) {\n",
    "        clustnum <- j\n",
    "        just1clust <- induced_subgraph(net, V(net)$clusters == j)\n",
    "        clustedges <- E(net)[E(net) %in% unlist(incident_edges(net, V(net)$clusters ==j))]\n",
    "        internalsum <- sum(abs(E(just1clust)$pcor))\n",
    "        totalsum <- sum(abs(clustedges$pcor))\n",
    "        clusterscore <- internalsum/totalsum\n",
    "        scoresvec[count] <- clusterscore\n",
    "        count = count+1\n",
    "        \n",
    "    }\n",
    "    colnames <- 'score'\n",
    "    returnthis <- as.data.frame(scoresvec)\n",
    "    rownames(returnthis) <- names(scoresvec)\n",
    "    colnames(returnthis) <- colnames\n",
    "    \n",
    "    # cluster size\n",
    "    if(sizes){\n",
    "        clustsizes <- as.data.frame((table(V(net)$clusters)))[,2]\n",
    "        returnthis <- cbind(returnthis, clustsizes)\n",
    "        colnames <- c(colnames, 'size')\n",
    "        colnames(returnthis) <- colnames\n",
    "    }\n",
    "   \n",
    "    # calculate pvals\n",
    "    if(calculate.p){\n",
    "        pvals <- vector(mode = 'numeric', length = length(scoresvec))\n",
    "        names(pvals) <- names(scoresvec)\n",
    "        for (k in length(scoresvec)){\n",
    "            realscore <- scoresvec[k]\n",
    "            nullishigher <- nulldist[nulldist > realscore]\n",
    "            pvalue <- length(nullishigher)/length(nulldist)\n",
    "            pvals[k] <- pvalue\n",
    "        }\n",
    "        colnames <- c(colnames, 'pvals')\n",
    "        returnthis <- (cbind(returnthis, pvals))\n",
    "        colnames(returnthis) <- colnames\n",
    "    }\n",
    "    \n",
    "    # max strength\n",
    "    if(max.str) {\n",
    "        strength <- vector(mode = 'numeric', length = length(scoresvec))\n",
    "        names(strength) <- names(scoresvec)\n",
    "        count <- 1\n",
    "        for(l in unique(clusters)[order(unique(clusters))]){\n",
    "            strength[count] <- max(V(net)[V(net)$clusters == l]$strength)\n",
    "            count <- count + 1\n",
    "        }\n",
    "        colnames <- c(colnames, 'max.str')\n",
    "        returnthis <- (cbind(returnthis, strength))\n",
    "        colnames(returnthis) <- colnames\n",
    "    }\n",
    "    # return a data frame\n",
    "    return(returnthis)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_score.help <- function(){\n",
    "    cat(\"THANK YOU FOR CALLING THE HELP DESK :)\")\n",
    "    cat(\"# This is a function that returns modularity-type scoring for individual clusters in a graph.\n",
    "\n",
    "    ## Clusters with a higher ratio of edge weights inside the cluster vs connecting to other\n",
    "    ## clusters will recieve a higher score. Clusters are scored on the scale of 0(worst) to 1(best).\n",
    "\n",
    "    # This function requires, at minimum, an igraph object with an edge attribute of 'pcor'.\n",
    "\n",
    "    # This function generates clusters through walktrap and cutreeDynamic. \n",
    "    ## Use parameter 't' to set walk length and 'minclusts' to set minimum cluster size.\n",
    "    ## Previously generated clusters (through any method, not just walktrap) can be imputed as \n",
    "    ## a membership vector through the parameter 'clusters'.\n",
    "\n",
    "    # If you want to calculate cluster size, set 'sizes = TRUE'\n",
    "    \n",
    "    ## If you want to calculate maximum strength per cluster, set 'max.str = TRUE'\n",
    "\n",
    "    # If you want to calculate p.value, set 'calculate.p = TRUE'\n",
    "    ## This function uses a monte carlo simulation to calculate p values. If you already generated a null \n",
    "    ## set, pass it to the function through the 'nulldist' parameter. If you have not, the function will\n",
    "    ## generate 1000 random clusters.\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell prevents the nbconvert code below from excuting when this module is loaded using \"source\" function\n",
    "FirstRun <- TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"[NbConvertApp] Converting notebook cluster_score.ipynb to script\"\n",
      "[2] \"[NbConvertApp] Writing 7210 bytes to cluster_score.r\"            \n"
     ]
    }
   ],
   "source": [
    "## Execute the next cell before running this cell to convert this file to an R script\n",
    "if (!FirstRun) print(osc(\"jupyter nbconvert cluster_score.ipynb --to script\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute this cell, and then the cell above to convert this file to an R script\n",
    "FirstRun <- FALSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
